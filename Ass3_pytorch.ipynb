{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ass3_pytorch.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "091fe97eb28844a29e608940c82af16d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a85ac3f81d5f4298b1b09ae81aba208f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e918935ffc0c420f9a960a593a407d6e",
              "IPY_MODEL_cedb671f4fc34a3ba05d8e1f8193f8c7"
            ]
          }
        },
        "a85ac3f81d5f4298b1b09ae81aba208f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e918935ffc0c420f9a960a593a407d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f51d00db8b4142cf913f836f71da801d",
            "_dom_classes": [],
            "description": " 19%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1758,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 333,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a86a4bf6717e4b8cbf3b07e1ced116c7"
          }
        },
        "cedb671f4fc34a3ba05d8e1f8193f8c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1be4cd992b0a41d48c50a04adfeee450",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 333/1758 [09:24&lt;40:57,  1.72s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cdbbdfd2f671411ca91528e2068829b5"
          }
        },
        "f51d00db8b4142cf913f836f71da801d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a86a4bf6717e4b8cbf3b07e1ced116c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1be4cd992b0a41d48c50a04adfeee450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cdbbdfd2f671411ca91528e2068829b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg9o9WQAK_tI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df9f21d-6188-4c9f-f05b-bee3811a2ac9"
      },
      "source": [
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "from torchtext.utils import download_from_url, extract_archive\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhjUAuUdZl3a",
        "outputId": "1c579a32-9161-40c3-8a66-f178fd81601f"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "source": [
        "# Dataset\n",
        "We used the Yandex corpus to train the model."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9kEL_eXZyzt"
      },
      "source": [
        "def build_vocab(filepath, language):\n",
        "  counter = Counter()\n",
        "  with io.open(filepath, encoding=\"utf8\") as f:\n",
        "    for i, string in enumerate(f):\n",
        "      counter.update(word_tokenize(string, language=language))\n",
        "\n",
        "      if i >= 20000: # We cannot add more words to the vocabulary because otherwise we will run out of resources\n",
        "          break\n",
        "  return Vocab(counter, specials=['<unk>', '<pad>', '<sos>', '<eos>'])\n",
        "\n",
        "ru_vocab = build_vocab('corp/corpus.en_ru.1m.ru', 'russian')\n",
        "en_vocab = build_vocab('corp/corpus.en_ru.1m.en', 'english')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO5bV46vS6N8"
      },
      "source": [
        "def make_pairs(en_file, ru_file):\n",
        "    raw_en_iter = iter(io.open(en_file, encoding=\"utf8\"))\n",
        "    raw_ru_iter = iter(io.open(ru_file, encoding=\"utf8\"))\n",
        "    data = []\n",
        "    for (raw_ru, raw_en) in zip(raw_ru_iter, raw_en_iter):\n",
        "        ru_tensor = torch.tensor([ru_vocab[token] for token in word_tokenize(raw_ru, language='russian')],\n",
        "                                dtype=torch.long)\n",
        "        en_tensor = torch.tensor([en_vocab[token] for token in word_tokenize(raw_en, language='english')],\n",
        "                                dtype=torch.long)\n",
        "        data.append((ru_tensor, en_tensor))\n",
        "\n",
        "    return data\n",
        "\n",
        "pairs = make_pairs('corp/corpus.en_ru.1m.en', 'corp/corpus.en_ru.1m.ru')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JztIbShsYuGy"
      },
      "source": [
        "PAD_IDX = ru_vocab['<pad>']\r\n",
        "SOS_IDX = ru_vocab['<sos>']\r\n",
        "EOS_IDX = ru_vocab['<eos>']\r\n",
        "\r\n",
        "def generate_batch(data_batch):\r\n",
        "    ru_batch, en_batch = [], []\r\n",
        "    for (ru_item, en_item) in data_batch:\r\n",
        "        ru_batch.append(torch.cat([torch.tensor([SOS_IDX]), ru_item, torch.tensor([EOS_IDX])], dim=0))\r\n",
        "        en_batch.append(torch.cat([torch.tensor([SOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\r\n",
        "    ru_batch = pad_sequence(ru_batch, padding_value=PAD_IDX)\r\n",
        "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\r\n",
        "    return ru_batch, en_batch"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-_v8Wa5X8pZ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_idx, valid_idx= train_test_split(\n",
        "np.arange(len(pairs)),\n",
        "test_size=0.1,\n",
        "shuffle=True)\n",
        "\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "valid_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
        "\n",
        "train_loader = DataLoader(pairs, batch_size=64, \n",
        "                        sampler=train_sampler, collate_fn=generate_batch)\n",
        "valid_loader = DataLoader(pairs, batch_size=64, \n",
        "                        sampler=valid_sampler, collate_fn=generate_batch)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oetLC_P_b-hB"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5aCSDDLb2jV"
      },
      "source": [
        "import random\n",
        "from typing import Tuple\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INPUT_DIM = len(ru_vocab)\n",
        "OUTPUT_DIM = len(en_vocab)\n",
        "\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ATTN_DIM = 64\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim ,enc_hid_dim, dec_hid_dim, dropout = 0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "\n",
        "        self.fc = nn.Linear(enc_hid_dim*2, dec_hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "\n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim, attn_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "\n",
        "        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
        "\n",
        "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
        "\n",
        "    def forward(self, decoder_hidden, encoder_outputs):\n",
        "\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((\n",
        "            repeated_decoder_hidden,\n",
        "            encoder_outputs),\n",
        "            dim = 2)))\n",
        "\n",
        "        attention = torch.sum(energy, dim=2)\n",
        "\n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "\n",
        "        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def _weighted_encoder_rep(self, decoder_hidden, encoder_outputs):\n",
        "\n",
        "        a = self.attention(decoder_hidden, encoder_outputs)\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
        "\n",
        "        return weighted_encoder_rep\n",
        "\n",
        "\n",
        "    def forward(self, input, decoder_hidden, encoder_outputs):\n",
        "\n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden,\n",
        "                                                          encoder_outputs)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
        "\n",
        "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
        "\n",
        "        output = self.out(torch.cat((output,\n",
        "                                     weighted_encoder_rep,\n",
        "                                     embedded), dim = 1))\n",
        "\n",
        "        return output, decoder_hidden.squeeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "\n",
        "        batch_size = src.shape[1]\n",
        "        max_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        output = trg[0,:]\n",
        "\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.max(1)[1]\n",
        "            output = (trg[t] if teacher_force else top1)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "\n",
        "def init_weights(model):\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "\n",
        "model.apply(init_weights)"
      ]
    },
    {
      "source": [
        "# Training"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, loader, optimizer, criterion, clip):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for src, trg in tqdm(loader):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for src, trg in tqdm(loader):\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "PAD_IDX = en_vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "N_EPOCHS = 3\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    print(f'Epoch: {epoch+1}/{N_EPOCHS}')\n",
        "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iter, criterion)\n",
        "    torch.save(model.state_dict(), '/seq2seq.h5')\n",
        "\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l33BG3kWpieO",
        "outputId": "e5f3b120-7aef-420a-9a9c-0f816bc64fbe"
      },
      "source": [
        "#model.load_state_dict(torch.load('seq2seq.h5'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "source": [
        "# Text translation"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvTrjhQlnfNt"
      },
      "source": [
        "results = []\n",
        "model.eval()\n",
        "PAD_IDX = ru_vocab['<pad>']\n",
        "SOS_IDX = ru_vocab['<sos>']\n",
        "EOS_IDX = ru_vocab['<eos>']\n",
        "\n",
        "with torch.no_grad():\n",
        "    k = 0\n",
        "    with io.open('/content/eval-ru-100.txt', encoding=\"utf8\") as f:\n",
        "        for string in f:\n",
        "            ru_tensor = torch.tensor([ru_vocab[token] for token in word_tokenize(string, language='russian')],\n",
        "                                    dtype=torch.long)\n",
        "            ru_tensor = [torch.cat([torch.tensor([SOS_IDX]), ru_tensor, torch.tensor([EOS_IDX])], dim=0)]\n",
        "\n",
        "            ru_tensor = pad_sequence(ru_tensor, padding_value=PAD_IDX)\n",
        "            \n",
        "            ru_tensor = ru_tensor.to(device)\n",
        "            encoder_outputs, hidden = model.encoder(ru_tensor)\n",
        "\n",
        "            outputs = torch.zeros(100, 1, len(en_vocab)).to(device)\n",
        "            \n",
        "            output = torch.tensor([en_vocab['<sos>']], dtype=torch.long).to(device)\n",
        "            for t in range(1, 100):\n",
        "                output, hidden = model.decoder(output, hidden, encoder_outputs)\n",
        "                outputs[t] = output\n",
        "                output = output.max(1)[1]\n",
        "            outputs = outputs[1:].view(-1, outputs.shape[-1])\n",
        "            res = ''\n",
        "            for out in outputs:\n",
        "                word = en_vocab.itos[out.max(0)[1]]\n",
        "                if word == '<eos>':\n",
        "                    break\n",
        "                res += ' ' + word\n",
        "            results.append(res)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OI7MqAtR47W"
      },
      "source": [
        "with open('answer.txt', 'w+') as f:\n",
        "    for i, line in enumerate(results):\n",
        "        if i == 100:\n",
        "            f.write(\"%s\" % line)\n",
        "        else:\n",
        "            f.write(\"%s\\n\" % line)"
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}