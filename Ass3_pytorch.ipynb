{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ass3_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7eN2E1dLwN3"
      },
      "source": [
        "1. Import all requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg9o9WQAK_tI"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import string\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzmD0xpmL2gF"
      },
      "source": [
        "2. Language class to help us with handling data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVFm4_LNLvUo"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "CAP_token = 2 # token for capitals\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"CAP\"}\n",
        "        self.n_words = 3  # count tokens\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGkP4hWWMoTw"
      },
      "source": [
        "Helper functions to turn Unicode to ASCII and normalize string (make all lowercase, remove all non-letter characters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqM4MXzmMn1t"
      },
      "source": [
        "import re\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.strip())\n",
        "    new_s = re.findall(r\"[\\w']+|[.,!?;\\-%]\", s)\n",
        "    normal_s = []\n",
        "    for word in new_s:\n",
        "#      if not word.lower() == word:\n",
        "#        normal_s.append(\"<CAP>\")\n",
        "      normal_s.append(word.lower())\n",
        "    return ' '.join(normal_s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFEWjyvsdbTt",
        "outputId": "a25692b5-a72e-4acd-aa4d-fe40cfba716c"
      },
      "source": [
        "s = normalizeString(\"Hello-world.\")\n",
        "print(s)\n",
        "print(len(s.split(\" \")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello - world .\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wlyWcw6NMms"
      },
      "source": [
        "Read sentences from files with input and output languages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOPpRAlJM_Zr"
      },
      "source": [
        "def readLangs():\n",
        "    print(\"Reading lines...\")   \n",
        "\n",
        "    en_lines = open('corpora/corpus.en_ru.1m.en', encoding='utf-8').read().strip().split('\\n')\n",
        "    ru_lines = open('corpora/corpus.en_ru.1m.ru', encoding='utf-8').read().strip().split('\\n')\n",
        "    # make sentence pairs\n",
        "    pairs = [(normalizeString(ru_lines[i]), normalizeString(en_lines[i])) \n",
        "            for i in range(len(ru_lines))]\n",
        "    input_lang = Lang('rus')\n",
        "    output_lang = Lang('eng')\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffa1BF5_VCvx"
      },
      "source": [
        "3. Data preparation step\n",
        "\n",
        "We read the sentences, fill languages with them. We also choose a certain amount of the data, which will speed up the process of learning and evaluating."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz_bRQdJRHf5",
        "outputId": "a7ce47fd-e4b1-462d-83cd-338a66596b5d"
      },
      "source": [
        "def prepareData(num):\n",
        "    input_lang, output_lang, pairs = readLangs()\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = random.sample(pairs, num)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData(1000)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 1000000 sentence pairs\n",
            "Trimmed to 1000 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 8935\n",
            "eng 5811\n",
            "('кнопка scan all forms of active project сканирует все формы приложения и выделяет из них те , которые содержат компоненты fibplus для работы с sql tpfibdataset , tpfibquery , tpfibupdateobject и tpfibstoredproc .', 'the button tscan all forms of active projectt scans all application forms and selects those which contain fibplus components for work with sql tpfibdataset , tpfibquery , tpfibupdateobject and tpfibstoredproc .')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDfop6MqVkQB"
      },
      "source": [
        "Sanity check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5SQXWFaTPo-",
        "outputId": "37153382-17ad-4c9c-adbc-8f413c916735"
      },
      "source": [
        "print(random.choice(pairs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('но они расчистят путь к нему .', 'but they will prepare the way to it .')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p--fBe6JW1Rb"
      },
      "source": [
        "ru_lens = [len(pair[0].split(' ')) for pair in pairs]\n",
        "en_lens = [len(pair[1].split(' ')) for pair in pairs]\n",
        "MAX_LENGTH = max(max(ru_lens), max(en_lens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG1kJoBylbZm",
        "outputId": "412c6983-b080-424e-9488-57e5418fb0d1"
      },
      "source": [
        "print(MAX_LENGTH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfLmFMu5VnIx"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YHkTmf0Vqz6"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR-NeNUKVvFn"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Wybz2B-WQ-B"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgAW6glzXj5n"
      },
      "source": [
        "teacher_forcing_ratio = 0.3\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKMdtBtpXnNb"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZZTG9w6Xn0g"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERC0QBLnYEiS"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2Vdvsu6YGKt"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CA0jY7D9YR6M",
        "outputId": "ff3e1832-634b-4fae-bcca-27c24906a151"
      },
      "source": [
        "hidden_size = 512\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 10000, print_every=100)\n",
        "\n",
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2m 12s (- 217m 55s) (100 1%) 5.2910\n",
            "4m 42s (- 230m 50s) (200 2%) 5.8530\n",
            "7m 25s (- 240m 13s) (300 3%) 5.7353\n",
            "9m 52s (- 236m 51s) (400 4%) 5.3150\n",
            "12m 29s (- 237m 11s) (500 5%) 5.5364\n",
            "15m 12s (- 238m 18s) (600 6%) 5.4340\n",
            "17m 52s (- 237m 31s) (700 7%) 5.7021\n",
            "20m 20s (- 233m 55s) (800 8%) 4.8859\n",
            "22m 35s (- 228m 30s) (900 9%) 4.7367\n",
            "25m 29s (- 229m 28s) (1000 10%) 5.8485\n",
            "27m 50s (- 225m 18s) (1100 11%) 5.1094\n",
            "30m 4s (- 220m 31s) (1200 12%) 4.4120\n",
            "32m 36s (- 218m 11s) (1300 13%) 5.5062\n",
            "35m 19s (- 217m 0s) (1400 14%) 5.3163\n",
            "37m 41s (- 213m 35s) (1500 15%) 5.0222\n",
            "40m 3s (- 210m 20s) (1600 16%) 5.0461\n",
            "42m 31s (- 207m 36s) (1700 17%) 4.9758\n",
            "45m 3s (- 205m 17s) (1800 18%) 5.4723\n",
            "47m 40s (- 203m 15s) (1900 19%) 5.1186\n",
            "50m 11s (- 200m 44s) (2000 20%) 5.1126\n",
            "52m 35s (- 197m 51s) (2100 21%) 5.3526\n",
            "55m 14s (- 195m 50s) (2200 22%) 5.4337\n",
            "57m 42s (- 193m 11s) (2300 23%) 5.3959\n",
            "60m 22s (- 191m 11s) (2400 24%) 5.2241\n",
            "63m 21s (- 190m 3s) (2500 25%) 5.5609\n",
            "65m 53s (- 187m 32s) (2600 26%) 5.0974\n",
            "68m 32s (- 185m 18s) (2700 27%) 5.3033\n",
            "70m 57s (- 182m 28s) (2800 28%) 4.8270\n",
            "73m 7s (- 179m 1s) (2900 28%) 5.2795\n",
            "75m 43s (- 176m 41s) (3000 30%) 5.3114\n",
            "78m 23s (- 174m 29s) (3100 31%) 5.3093\n",
            "80m 49s (- 171m 44s) (3200 32%) 5.1737\n",
            "83m 23s (- 169m 18s) (3300 33%) 5.1562\n",
            "85m 47s (- 166m 31s) (3400 34%) 5.1077\n",
            "88m 17s (- 163m 58s) (3500 35%) 5.2379\n",
            "90m 50s (- 161m 29s) (3600 36%) 5.2866\n",
            "93m 24s (- 159m 3s) (3700 37%) 5.1016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c8c1192c3061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mevaluateRandomly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-83046cb015eb>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, learning_rate)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         loss = train(input_tensor, target_tensor, encoder,\n\u001b[0;32m---> 17\u001b[0;31m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-aec8da2a4324>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     18\u001b[0m         encoder_output, encoder_hidden = encoder(\n\u001b[1;32m     19\u001b[0m             input_tensor[ei], encoder_hidden)\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSOS_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 346 is out of bounds for dimension 0 with size 346"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oG-_HeRHpc20",
        "outputId": "b7314ba5-5009-4a58-982f-b9664806aa5c"
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> с целью пополнения ресурснои базы в 2006 году в казахстане были объявлены открытые конкурсы на получение права недропользования по 111 объектам в том числе 23  по углеводородному сырью\n",
            "= in 2006 to extend the resource base kazakhstan held open tenders for 111 mining fields including 23 hydrocarbon fields\n",
            "< in to to to to to the other countries notably italy bodes well for russia in his own to and <EOS>\n",
            "\n",
            "> глобальныи бизнес\n",
            "= above the clouds flight takeoff\n",
            "< the the and the the the <EOS>\n",
            "\n",
            "> окно справа станет чуть более темным с наложеннои на него стрелкои указывающеи направо\n",
            "= the upper window will get a little darker overlaid with an arrow pointing up\n",
            "< the with a with the will a the the the the the with the the a the the with a <EOS>\n",
            "\n",
            "> shooting часа в настоящее время на веблучшии дешевои насколько это возможно пожалуиста принимающеи все функции необходимые для спасения жизни много головнои боли в будущем\n",
            "= taking time now to find the best possible cheap web hosting with all the features you need will save you from many headaches in the future\n",
            "< taking time now to the the where the the of the the in the of the the and not in to of the the a the for the of of the and <EOS>\n",
            "\n",
            "> все посылки помощи предназначенные для интернированных освобождаются от таможенных пошлин и других сборов\n",
            "= all relief shipments for prisoners of war shall be exempt from import customs and other dues\n",
            "< all of of war shall be given to any of of and <EOS>\n",
            "\n",
            "> многие из стареишин осмотрели рисунок прежде чем школьныи комитет вызвал иосифа и потребовал чтобы тот принял меры для пресечения беззаконии своего старшего сына\n",
            "= there it was plain as day and many of the elders had viewed it before the committee went to call on joseph to demand that something be done to suppress the lawlessness of his eldest son\n",
            "< there it was not be as as and as the as the and as the and as the as the and as the the the and as the as the and as the the and <EOS>\n",
            "\n",
            "> 1 решения ооо «гоулаиф» по управлению жизненным циклом продукта позволяют заказчику •• создавать и выпускать инновационные продукты удовлетворяющие или создающие рыночныи спрос •• оптимизировать процессы и системы разработки для ускорения вывода продук тов на рынок обеспечивая соответствие отраслевым качественным и нормативным стандартам конкурентные возможности в своих бизнессетях •• стать более маневренными чем конкуренты и выгодно использовать рыночные и решения по управлению жизненным циклом продукта\n",
            "= golife llc solutions on product lifecycle management enable the customer to • create and issue innovative products satisfying or creating market demand • optimize processes and development systems to accelerate product launch on the market assuring compliance with industrial quality and regulatory standards sibilities in one’s business networks • become more flexible than competitors and make profit of market and competitive posproduct lifecycle management\n",
            "< golife llc on on on the the the the the the and the the and on the the and to the and <EOS>\n",
            "\n",
            "> проблема в другом если мы останавливаемся на достигнутом имея лучшую руду в мире и добываем только 13 млн тонн то мы автоматически становимся планово депрессивнои компаниеи\n",
            "= the issue lies elsewhere if we are merely content to rest on our laurels and continue to mine only 13 million tonnes while we have the best ore in the world then we automatically become a planned underperforming company\n",
            "< the are the are the we are are to are it to our the the the their of on to which on to and all on on the and if it <EOS>\n",
            "\n",
            "> в истории земли насчитывается по меньшеи мере пять периодов когда за относительно короткое время исчезло множество видов животных и растении\n",
            "= the earth remembers at least five periods during which almost all animals and plants were erased from our planets face\n",
            "< the at least least the the the of the and the and and and <EOS>\n",
            "\n",
            "> в центре города находится мавзолеиусыпальница русских и румынских воинов погибших под плевеном пл возрождения 5 тел 064 30033\n",
            "= in the centre of the town there is a mausoleumcharnel house dedicated to the russian and romanian soldiers killed during the war 5 vuzrazhdane square tel\n",
            "< in the centre of there is the the of the the and the the and in the the and and <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}